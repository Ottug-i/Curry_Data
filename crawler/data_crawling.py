# -*- coding: utf-8 -*-
"""Data_Crawling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11b7GkLaVWJTVs_O9YdmOIMn79szVXom9

# 공공 데이터 가져오기
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

# 만개의 레시피 공공 데이터 불러오기
recipe = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/크롤링/recipe.csv', encoding='cp949')

# 인덱스 설정
recipe.set_index('id', inplace = True)

recipe.sample()

# 레시피 id 리스트
id_list = recipe.index.to_list()
print(len(id_list))

"""# 공공 데이터에 크롤링 정보 추가하기"""

!pip install BeautifulSoup4

import requests
from bs4 import BeautifulSoup
import re

# 레시피 id로 레시피 추가 정보 크롤링

recipe_thumbnail = [] # 레시피 썸네일
recipe_time = [] # 레시피 시간
recipe_orders = [] # 레시피 조리 순서
recipe_photo = [] # 레시피 사진
    
def RecipeCrawler(recipeId):
    
    url = f'https://www.10000recipe.com/recipe/{recipeId}'

    response = requests.get(url)
    html = response.text
    soup = BeautifulSoup(html, 'html.parser')

    # 레시피 썸네일
    try:
        thumbnail = soup.select_one('#contents_area > div.view2_pic > div.centeredcrop img')['src']
        recipe_thumbnail.append(thumbnail)
    except AttributeError:
        recipe_thumbnail.append('')
    pass

    # 레시피 시간
    try:
        time = soup.select_one('#contents_area > div.view2_summary.st3 > div.view2_summary_info > span.view2_summary_info2').get_text()
        recipe_time.append(time)
    except AttributeError:
        recipe_time.append('')
    pass

    # 레시피 조리 순서
    try:
        elements = soup.find_all('div', 'view_step_cont')
        tmp = ''
        for i, element in enumerate(elements, start=1):
            order = element.find('div', 'media-body')
            order = ''.join(order.findAll(string=True, recursive=False)).strip() # 조리 순서에서 설명, 주방 도구 제외
            tmp = tmp + ('|' + str(i) + '. ' + order)
        recipe_orders.append(tmp)
    except AttributeError:
        recipe_orders.append('')
    pass

    # 레시피 조리 사진
    try:
        elements = soup.find_all('div', 'view_step_cont')
        tmp = ''
        for i, element in enumerate(elements, start=1):
            try:
                photo = element.find('img')['src']
                tmp = tmp + ('|' + photo)
            except TypeError:
                tmp = tmp + ('|' + ' ')
            pass
        recipe_photo.append(tmp)
    except AttributeError:
        recipe_photo.append('')
    pass

# 10개만 테스트
for i, id in enumerate(id_list[:10], start=1):
    print(str(i) + "번째 크롤링 id: " + str(id))
    RecipeCrawler(id)

# 10개만 테스트
curry_recipe = recipe[:10]

# 추가 정보 열 추가
curry_recipe['thumbanil'] = recipe_thumbnail
curry_recipe['time'] = recipe_time
curry_recipe['orders'] = recipe_orders
curry_recipe['photo'] = recipe_photo

curry_recipe.sample()

"""# CSV 파일 내보내기"""

# csv 파일 내보내기
curry_recipe.to_csv('curry_recipe.csv', encoding='utf-8-sig')